System:
Solve the following coding problem. Wrap your code answer using ```


Question:
Implement batch gradient descent using JAX's automatic differentiation (`jax.grad`) to optimize a linear regression model. Compare the model's performance with stochastic gradient descent (SGD).


Answer:
Here's how you can implement batch gradient descent using JAX's automatic differentiation:

```python
import jax
import jax.numpy as jnp

def loss_fn(params, X, y):
    y_pred = jnp.dot(X, params)
    return jnp.mean((y - y_pred) ** 2)

def grad_loss_fn(params, X, y):
    return jax.grad(loss_fn)(params, X, y)

def batch_gradient_descent(params, X, y, learning_rate, num_iterations):
    for _ in range(num_iterations):
        grads = grad_loss_fn(params, X, y)
        params = params - learning_rate * grads
    return params
```

Batch gradient descent updates the model parameters by taking the average of the gradients over the entire dataset. This ensures that the model parameters are updated based on the entire dataset, which can lead to faster convergence but may be computationally expensive for large datasets.

Stochastic gradient descent (SGD) updates the model parameters by taking the gradient of the loss function with respect to the model parameters for a single randomly selected example from the dataset. This approach is more computationally efficient than batch gradient descent but may lead to slower convergence.

Here's how you can compare the performance of batch gradient descent and SGD:

```python
import numpy as np

np.random.seed(42)
X = np.random.randn(100, 10)
y = np.random.randn(100, 1)
params = np.zeros(10)
learning_rate = 0.01
num_iterations = 1000

params_batch = batch_gradient_descent(params, X, y, learning_rate, num_iterations)
params_sgd = params
for _ in range(num_iterations):
    i = np.random.randint(0, 100)
    grads = grad_loss_fn(params_sgd, X[i], y[i])
    params_sgd = params_sgd - learning_rate * grads

loss_batch = loss_fn(params_batch, X, y)
loss_sgd = loss_
